<!DOCTYPE html>
<meta charset="UTF-8">

<title>Modeling Machine And Human States To Enable And Evaluate Secure
Usability</title>

<style>
body {
  margin: 1in;
  line-height: 1.4;
  font-family: "Roboto", "San Francisco", "Helvetica Neue", "Helvetica", "Arial", sans-serif;
  width: 45em;
}
</style>

<h1>Modeling Machine And Human States To Enable And Evaluate Secure
Usability</h1>

<p>Chris Palmer, <a
href="mailto:chris@noncombatant.org">chris@noncombatant.org</a></p>

<h2>Abstract</h2>

<p>TODO</p>

<h2>Introduction</h2>

<p>We can describe or model much of a software program’s behavior as transitions
from 1 state to another. The same is true of the behavior of computing hardware,
as well as protocols and ceremonies. In this paper, the generic term
<em>machine</em> refers to any software, hardware, protocol, or ceremony.</p>

<p>Good user experience (UX) engineering should help people to develop
accurate-enough mental models of the machine’s state. (See for example <a
href="http://www.nngroup.com/articles/mental-models/">“Mental Models” by Jakob
Nielsen</a>. TODO: Find better/more citations.) In order to do that, we need to
develop a model of the state transitions the human makes as well as those the
machine makes. We must also estimate the probability that the human’s model
accurately tracks that of the machine, where necessary. (It is rarely necessary
or possible for the human to track the machine’s state exactly.)</p>

<p>When the human cannot track the machine’s state accurately enough, poor
usability results. The human has a hard time understanding what the machine is
doing, and loses confidence that they can control the machine and complete their
task.</p>

<p>Some state tracking mismatches are also security vulnerabilities. For
example, if the human believes that a communications application is using
cryptography to secure the person’s messages to and from their friend, but in
fact the application is <em>not</em> doing that, the person may engage in
unnecessarily risky behavior, may lose control of private information, may lose
control of payment instruments, and so on. For another example, if the human
believes that the computer is showing them the login screen for their bank, but
in fact the login screen is controlled by an impostor, the person is likely to
lose control of their bank account.</p>

<p>It can also be the case that the person underestimates the security level of
the machine’s state, and hence is over-cautious. In this case, the person may
not receive the full utility or value of the application.</p>

<p>Therefore, for good usability as well as good security, UX engineers must be
able to predict what states a mental model the human will traverse as they use
the system. Engineers must create affordances, select iconography and labels,
and use gestures that help people develop accurate-enough mental models, and
which are more likely than not to guide the person through the states of their
mental model that accurately map to machine states.</p>

<p>Approaching UX engineering from this perspective allows us to dissolve the
false dichotomy between usability (sometimes grossly mischaracterized as mere
‘convenience’) and security. In fact, in this article I hope to show that the
interfaces that are the most learnable, discoverable, accessible, and effective
are also the ones that have the fewest human-machine state mismatches — and
hence the fewest human-machine state mismatches that lead to vulnerability.</p>

<h2>Prior Work</h2>

<p><a
href="http://projecteuclid.org/download/pdf_1/euclid.aoms/1177699147">Hidden
Markov models</a></p>

<p><a href="https://eprint.iacr.org/2007/399.pdf"><em>Ceremony Design And
Analysis</em></a> by Carl Ellison</p>

<p>TODO. Adrienne sent more good ones.</p>

<h2>Hello, World</h2>

<p>Consider the state transition diagram for the simplest possible UX control: A
button that sets a Boolean value in the program’s internal state. Assume it’s a
program variable to require (<var>true</var>) or not require (<var>false</var>)
that the program use only encrypted network communications.</p>

<div>
<img src="01-simple-boolean.png"/><br/>
<em>Figure 1: A simple Boolean option.</em>
</div>

<p>To change states, the person performs a <em>gesture</em> (in this case,
clicks the button). With each click, the machine enters the 1 other possible
state; there are no other possible states. The machine changes state with
perfect certainty; there are no bugs in the hypothetical <var>onclick</var>
event handler. We may presume that the person perceives the state change, both
because they had to perform a gesture to make it happen, and because the visual
representation of the button changes from <em>raised</em> to
<em>pressed</em>.</p>

<p>UX designers and engineers know from painful experience that people do not,
in fact, always have perfect perception of the changes that happen in the
machine’s state, even with such ‘obvious’ causes as the person’s own click
gesture, and with such ‘obvious’ effects as the change in the visual appearance
of the button. For examples of why this might happen, consider:</p>

<ul>

<li>this might be the person’s first time using a computer, and they might not
understand the significance of the click gesture and the visual representation
of the button</li>

<li>the graphic design of the UX elements may have changed since the last
software update, and the person has not yet learned the new appearance for
<em>raised</em> and <em>pressed</em> buttons</li>

<li>the person may not be sure if the machine recognized the gesture</li>

<li>the machine may not update the visual representation in time (“jank”) or
otherwise handle the event in real time</li>

</ul>

<p>There is a certain probability that the person is confused in 1 (or more) of
these ways. To start, we may assume that it is highly probable that the person’s
mental model can track the machine’s state model; assume that the probability of
correct tracking is 0.9. Further assume that the probability of incorrect
tracking is 0.1. In Figure 2, square vertices indicate incorrect human mental
states, and the arcs are marked with their probabilities. Additionally, the arcs
are shown in light gray for low probability, and in dark gray for high
probability.</p>

<div>
<img src="02-simple-boolean-with-confusion.png"/><br/>
<em>Figure 2: A simple Boolean option, allowing for human confusion.</em>
</div>

<p>Sometimes people can be confused about what states are even possible in the
machine’s state model. In this example, there are 2 different types of
confusion: whether or not the button is pressed and encryption is turned on; and
what the security guarantee of the encryption really is. (People often
mistakenly believe that encryption alone also provides authentication of the
peer or the tamper-evidence of the data they transmit over the connection.)</p>

<div>
<img src="03-simple-boolean-with-orthogonal-states.png"/><br/>
<em>Figure 3: A simple Boolean option, allowing for human confusion as to what
states are even possible for the machine.</em>
</div>

<p>TODO: the situation when the human’s model of the machine state model is
inaccurate or incomplete, both in ways that do not matter and in ways that
do</p>

<h2>Basic Constraints</h2>

<p>All arcs out of a vertex have a corresponding probability that the person’s
mental state will change to the indicated state, and the probabilities of all
arcs leading out from a state must add up to exactly <var>p</var> = 1.0.</p>

<p>There is 1 exception to this rule: the <em>secure attention
sequence</em>.</p>

<h3>The Secure Attention Sequence</h3>

<p>A secure attention sequence (SAS) is any gesture which</p>

<ul>

<li>the underlying platform interprets without passing the gesture through to
potentially untrustworthy, lower-privilege code</li>

<li>always causes the platform to run only code from its trusted computing
base</li>

<li>the trustworthy code always shows trustworthy (unforgeable,
un-eavesdroppable) UI</li>

</ul>

<p>Despite the name ‘sequence’, the gesture may be a simple one like pressing
<em>Escape</em> on the keyboard or the <em>Home</em> button on an iOS device.
The term ‘sequence’ may be a historical quirk: one of the first SASs was the
Windows and OS/2 SAS, the complex keyboard gesture
<em>Control-Alt-Delete</em>.</p>

<p>Possible example SASs:</p>

<ul>

<li>Control-Alt-Delete on Windows (the GINA/modern equivalent TODO runs in its
own desktop and as its own principal)</li>

<li>The Home button on iOS devices</li>

<li>Anything on Chrome OS?</li>

</ul>

<p>Requirements for a SAS:</p>

<ul>

<li>all arcs must point to the same vertex, the <em>SAS target</em></li>

<li>the SAS target must not be an incorrect (square) state</li>

<li>every vertex other than the SAS target must have exactly 1 arc, with <var>p</var> =
1.0, leading to the SAS target</li>

</ul>

<p>In these graphs, we will color the arcs pointing to the SAS target in red.
To keep the graphs clean, we will give them no other marking; you may assume
that the properties of a SAS hold if the graph has a SAS at all, that the
SAS gesture is unique and global to the machine, and that the probability that
the human tracks it is 1.0..</p>

<div>
<img src="04-simple-boolean-with-reset.png"/><br/>
<em>Figure 4: A simple Boolean option, with a secure attention sequence to reset
to the default state.</em>
</div>

<p>However, even that is messy. To keep the graphs even more clean, we may color
the SAS target red, use a double-circle for its node, and omit the arcs pointing
to it.</p>

<div>
<img src="05-simple-boolean-with-reset-clean.png"/><br/>
<em>Figure 5: A simple Boolean option, with a secure attention sequence to reset
to the default state.</em>
</div>

<p>If a graph has no SAS target node, then it is a model of a machine that has
no SAS.</p>

<h2>Example: Full Screen Mode</h2>

<p>Consider a more complex model of machine and human state: A full-screen mode
for a web browser. Various classes of web application (e.g. games, slideshow and
other document viewers, demos, signage) benefit greatly from the ability to use
the entire screen, obscuring not only the native chrome of the browser but that
of the underlying operating system. Obviously, this is potentially damaging to
the person’s mental model of what the machine is doing, because they lose the
ability to read or interact with the native controls — many of which are
security-critical. (Consider, for example, the browser’s Location Bar, or the
operating system’s privilege escalation dialog.)</p>

<p>Thus, if the browser supports full screen mode, a malicious web application
author has a marginally improved ability to spoof the UX and fool the person
using it. For example, they might create a screen that obscures native chrome
that lets the person know that they are viewing a particular origin, and
replacing it with impostor chrome that tricks the person into thinking they are
visiting another origin. The person might then be induced to provide the
impostor origin with their credentials for the true origin.</p>

<p>Feross Aboukhadijeh has developed <a
href="http://feross.org/html5-fullscreen-api-attack/">an example of such a
spoofing attack</a>. The attack goes to some effort to mimic the chrome of the
browser and even the underlying operating system, and seeks to spoof the web
site of a large US bank. Because Aboukhadijeh is not really seeking to trick
people, the demo warns the person that they were tricked if they try to interact
with the impostor page.</p>

<p>Here is how the spoof demo looks in Chrome 46. When the person clicks on the
link on Aboukhadijeh’s page, a new window opens and takes up the full screen,
showing a fake Bank Of America page. Chrome 46 shows an overlay over the window,
near the top, telling the person that “feross.org is now full screen” and that
they can <em>Allow</em> this (dismissing the overlay) or <em>Exit full
screen</em> (closing the full screen window).</p>

<div>
<img src="feross-01.png"/><br/>
<em>Figure 6a: A spoof of Bank Of America using full-screen mode. The
Allow/Exit overlay is showing.</em>
</div>

<p>Assuming the person chooses to Allow feross.org to take the whole screen
(something that only TODO% of people do; TODO talk about the numbers), Chrome
shows a new overlay, with just a notification and without buttons:</p>

<div>
<img src="feross-02.png"/><br/>
<em>Figure 6b: A spoof of Bank Of America using full-screen mode. The
notification overlay is showing.</em>
</div>

<p>After a few seconds, this new overlay disappears, and the application is now
running unfettered in full screen mode:</p>

<div>
<img src="feross-03.png"/><br/>
<em>Figure 6c: A spoof of Bank Of America using full-screen mode. No overlays
are showing; the application has full control of all pixels on the screen.</em>
</div>

<p>However, if the person touches the mouse to the top of the screen, the
button-less overlay reappears, re-asserting to the person that they are seeing
feross.org in full screen mode.</p>

<p>Here is what my screen looks like when I browse to the true Bank Of America
site with my browser window maximized. The true Bank Of America site does not
use the full screen feature, so my true browser chrome and my true operating
system chrome is still visible:</p>

<div>
<img src="feross-04.png"/><br/>
<em>Figure 6d: The real Bank Of America site, not in full screen mode but
maximized, with the true native browser chrome and Ubuntu window management
chrome.</em>
</div>

<p>Without going to the effort of using full screen mode to create an elaborate
spoof, such an attacker has a good probability of success due to the reality
that people check the browser’s origin indicators with <var>p</var> well below
1.0 — and then, the probability that the person fully understands what the
indicators mean is also below 1.0.</p>

<p>TODO: Discuss the Feross screenshots vs. a simpler spoof on
noncombatant.org.</p>

<p>Even so, we would like to help people model the full screen state of the
machine, while at the same time not degrading the functionality of a benign full
screen application. TODO: Reasons... frustration with decorations messing with
games; complaints from people who get stuck in FS; et c. TODO: Explain this
beast:</p>

<div>
<img src="07-full-screen.png"/><br/>
<em>Figure 7: A full-screen mode that attempts to protect against UX
spoofing.</em>
</div>

<h2>Example: Origin Security Indicators</h2>

<p>TODO</p>

<h2>Acknowledgments</h2>

<p>I’d like to thank the Academy, and Jesus.</p>

<!--

TODO and writing style guidelines:

* Avoid saying ‘user’
* Avoid the passive voice
* Prefer verb phrases to gerunds

-->
